
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Case Study: Modularizing Language Components}
\label{chap:case_study}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To further illustrate the applicability of \sedel, we present a case
study using Object Algebras~\citep{oliveira2012extensibility} and
Extensible \textsc{Visitor}s~\citep{oliveira09modular, togersen:2004}. Encodings
of extensible designs for Object Algebras and Extensible \textsc{Visitor}s have
been presented in mainstream languages~\citep{oliveira09modular, togersen:2004, oliveira2012extensibility, oliveira2013feature, rendel14attributes}.
However, prior approaches are not entirely satisfactory
due to the limitations in existing mainstream OO languages. In \cref{sec:ob}, we show how \sedel makes those designs significantly simpler and
convenient to use. In particular, \sedel's encoding of extensible visitors gives true ASTs and supports
conflict-free Object Algebra combinators, thanks to first-class traits and disjoint polymorphism.
Based on this technique, \cref{sec:case} gives a bird's-eye view of several orthogonal features of
a small JavaScript-like language from a textbook on Programming
Languages~\citep{poplcook}, and illustrates how various features can
be modularly developed and composed to assemble a complete language with various
operations baked in. \Cref{sec:evaluate} compares our \sedel's implementation
with that of the textbook using Haskell in terms of lines of code.


\section{Object Algebras and Extensible Visitors in \sedel}
\label{sec:ob}

First we give a simple introduction to Object Algebras, a design pattern that
can solve the Expression Problem~\citep{wadler1998expression} (EP) in languages like
Java. The objective of EP is to \emph{modularly} extend a datatype in two
dimensions: by adding more cases to the datatype and by adding new operations
for the datatype.
Our starting point is the following code:
\lstinputlisting[linerange=4-17]{./examples/application.sl}% APPLY:linerange=ALGEBRA_DEF
\lstinline{ExpAlg[E]} is the generic interface of a simple arithmetic language
with two cases, \lstinline{lit} for literals and \lstinline{add} for addition.
\lstinline{ExpAlg[E]} is also referred to as an Object Algebra interface. A concrete
Object Algebra will implement such an interface by instantiating \lstinline{E}
with a suitable type. Here we also define one operation \lstinline{IEval},
modelled by a single-field record type. A concrete Object Algebra that
implements the evaluation rules is given by a trait
\lstinline{evalAlg}.

\paragraph{First-Class Object Algebra Values.}
The actual AST of this simple arithmetic language is given as an internal
visitor~\citep{Oliveira_2008}:
\lstinputlisting[linerange=21-23]{./examples/application.sl}% APPLY:linerange=EXP_TYPE
Note that Object Algebras as implemented in languages like Java or Scala do not define the type
\lstinline{Exp} because this would make adding new variants very hard. Although extensible versions
of this visitor pattern do exist, they usually require complex types using advanced features of
generics~\citep{oliveira2012extensibility, togersen:2004}.
However, as we will see, this is not a problem in \sedel. We can build a value of \lstinline{Exp} as follows:
\lstinputlisting[linerange=27-29]{./examples/application.sl}% APPLY:linerange=VALUE_E1


\paragraph{Adding a New Operation.}
We add another operation \lstinline{IPrint} to the language:
\lstinputlisting[linerange=34-42]{./examples/application.sl}% APPLY:linerange=PRINT_DEF
This is done by giving another trait \lstinline{printAlg} that implements the
additional \lstinline{print} method.


\paragraph{Adding a New Case.}
A second dimension for extension is to add another case for negation:
\lstinputlisting[linerange=47-57]{./examples/application.sl}% APPLY:linerange=SUB_DEF
This is achieved by extending \lstinline{evalAlg} and \lstinline{printAlg}, implementing
missing operations for negation, respectively. We define the actual AST similarly:
\lstinputlisting[linerange=62-64]{./examples/application.sl}% APPLY:linerange=EXPEXT_TYPE
and build a value of \lstinline{-(2 + 3)} while reusing \lstinline{e1}:
\lstinputlisting[linerange=69-71]{./examples/application.sl}% APPLY:linerange=VALUE_E2

\paragraph{Relations between \lstinline{Exp} and \lstinline{ExpExt}}
At this stage, it is interesting to point out an interesting subtyping relation
between \lstinline{Exp} and \lstinline{ExtExp}: \lstinline{ExpExt}, though being an
\emph{extension} of \lstinline{Exp} is actually a \emph{supertype} of \lstinline{Exp}.
As Oliveira~\citep{oliveira09modular} observed, these relations are
important for legacy and performance reasons since it means that, a value of
type \lstinline{Exp} can be \emph{automatically} and \emph{safely}
coerced into a value of type \lstinline{ExpExt}, allowing some
interoperability between new functionality and legacy code.
However, to ensure type-soundness, Scala (or other common OO languages) forbids any kind of type-refinement on method
parameter types. The consequence of this is that in those languages, it is
impossible to express that \lstinline{ExtExp} is both an extension and a
supertype of \lstinline{Exp}.


% Encodings
% of extensible visitors in mainstream OO languages usually fail to
% correctly express these relations, or require sophisticated
% type system extensions~\citep{oliveira09modular}.


\section{Dynamic Object Algebra Composition Support}

When programming with Object Algebras, oftentimes it is necessary to compose
multiple operations together in such a way that they are executed in parallel to
the same input. For example, in the simple language we have been developing it
can be useful to create an object that supports both printing and evaluation.
Oliveira and Cook~\citep{oliveira2012extensibility} addressed this problem by
proposing \emph{Object Algebra combinators} that combine multiple algebras into
one. However, as they noted, such combinators written in Java are difficult to
use in practice, and they require significant amounts of boilerplate. Improved
variants of Object Algebra combinators have been encoded in Scala using
intersection types and an encoding of the merge
construct~\citep{oliveira2013feature, rendel14attributes}. However, the Scala
encoding of the merge construct is quite complex as it relies on low-level
type-unsafe programming features such as dynamic proxies, reflection or other
meta-programming techniques. In \sedel, the combination of first-class traits,
dynamic inheritance, disjoint polymorphism and nested composition allows type-safe, coherent and
boilerplate-free composition of Object Algebras.

Abstractly speaking, what we are seeking is a combinator:
\[
  \mathsf{combine} \in F[A] \times F[B] \rightarrow F[A\ \&\ B]
\]
That is, given two algebras with types $F[A]$ and $F[B]$ we want to
derive, in a automatic way, a third algebra $F[A\ \&\ B]$ that combines the results
of the two algebras. This combinator bears a similarity to a
\lstinline{zip}-like operation in functional programming, and it is also directly
related to nested composition in object-oriented programming, as we have studied
in \cref{chap:nested}. Without further due, here is the definition of a Object
Algebra combinator in \sedel:
\lstinputlisting[linerange=76-78]{./examples/application.sl}% APPLY:linerange=COMBINE
That is it. None of the boilerplate in other
approaches~\citep{oliveira2012extensibility}, or type-unsafe meta-programming
techniques of other approaches~\citep{oliveira2013feature,rendel14attributes} are
needed! Three points are worth noting:
\begin{inparaenum}[(1)]
\item \lstinline{combine} relies on \emph{dynamic inheritance}. Notice how
  \lstinline{combine} is parameterized by two traits \lstinline{f} and \lstinline{g}, for
  which their implementations are unknown statically;
\item the disjointness constraint (\lstinline{B * A}) is \emph{crucial} to
  ensure two algebras (\lstinline{f} and \lstinline{g}) are conflict-free
  when being composed;
\item nested composition is the underlying mechanism to automatically derive the
  combined algebra by appropriately invoking (delegating) behaviors in $A \ \&\ B$ to either $A$ or $B$.
\end{inparaenum}
To conclude, let us see \lstinline{combine} in action. We merge the evaluation
and printing algebras to create an \lstinline{expEvalPrint} algebra:
\lstinputlisting[linerange=82-82]{./examples/application.sl}% APPLY:linerange=NEW_ALG
We can use this algebra to create an object \lstinline{o} that allows us to use
evaluation and pretty printing at the same time:
\lstinputlisting[linerange=87-89]{./examples/application.sl}% APPLY:linerange=USE




\begin{figure}[t]
\centering
\begin{tabular}{lrclr}
  Types  & $\tau$ & ::= & $ \mathsf{int}  \mid  \mathsf{bool} $ & \\
  Expressions & $e$ & ::= & $ i  \mid \,  \ottnt{e_{{\mathrm{1}}}}  \ottsym{+}  \ottnt{e_{{\mathrm{2}}}} \mid \,  \ottnt{e_{{\mathrm{1}}}}  \ottsym{-}  \ottnt{e_{{\mathrm{2}}}} \mid \,  \ottnt{e_{{\mathrm{1}}}}  \times  \ottnt{e_{{\mathrm{2}}}} \mid \,  \ottnt{e_{{\mathrm{1}}}}  \div  \ottnt{e_{{\mathrm{2}}}} $ & $\mathit{natF}$ \\
              && $\mid$ & $ \mathbb{B}  \mid \ottkw{if} \, \ottnt{e_{{\mathrm{1}}}} \, \ottkw{then} \, \ottnt{e_{{\mathrm{2}}}} \, \ottkw{else} \, \ottnt{e_{{\mathrm{3}}}} $ & $\mathit{boolF}$\\
              && $\mid$ & $ \,  \ottnt{e_{{\mathrm{1}}}}  \ottsym{==}  \ottnt{e_{{\mathrm{2}}}} \mid \,  \ottnt{e_{{\mathrm{1}}}}  \ottsym{<}  \ottnt{e_{{\mathrm{2}}}} $ & $\mathit{compF}$ \\
              && $\mid$ & $ \,  \ottnt{e_{{\mathrm{1}}}}  \,\&\&\,  \ottnt{e_{{\mathrm{2}}}} \mid \,  \ottnt{e_{{\mathrm{1}}}}  \,||\,  \ottnt{e_{{\mathrm{2}}}} $ & $\mathit{logicF}$ \\
              && $\mid$ & $\ottmv{x} \mid \ottkw{var} \, \ottmv{x}  \ottsym{=}  \ottnt{e_{{\mathrm{1}}}}  \ottsym{;}  \ottnt{e_{{\mathrm{2}}}}$  &  $\mathit{varF}$ \\
              && $\mid$ & $\,  \ottnt{e_{{\mathrm{1}}}} \, \ottnt{e_{{\mathrm{2}}}}$ & $\mathit{funcF}$ \\
  Programs & $pgm$ & ::= & $decl_{{\mathrm{1}}} \dots decl_{\ottmv{n}} \, \ottnt{e}$ &  $\mathit{funcF}$ \\
  Functions & $decl$ & ::= & $\ottkw{function} \, \ottmv{f}  \ottsym{(}  \ottmv{x}  \ottsym{:}  \tau  \ottsym{)}  \ottsym{\{}  \ottnt{e}  \ottsym{\}}$ &  $\mathit{funcF}$ \\
  Values & $v$ & ::= & $ i  \mid  \mathbb{B} $ &
\end{tabular}

\caption{Mini-JS expressions, values, and types}
\label{fig:mini-js}
\end{figure}

\section{Case Study Overview}
\label{sec:case}

Now we are ready to see how the same technique scales to modularize different
language features. A \emph{feature} is an increment in program
functionality~\citep{zave1999faq,lopez2005evaluating}. \Cref{fig:mini-js}
presents the syntax of the expressions, values and types provided by the
features; each line is annotated with the corresponding feature name. Starting from a
simple arithmetic language, we gradually introduce new features and combine them
with some of the existing features to form various languages. Below we briefly
explain what constitutes each feature:
\begin{itemize}
\item $\mathit{natF}$ and $\mathit{boolF}$ contain, among others, literals, additions and conditional expressions.
\item $\mathit{compF}$ and $\mathit{logicF}$ introduce comparisons between numbers and logical connectives.
\item $\mathit{varF}$ introduces local variables and variable declarations.
\item $\mathit{funcF}$ introduces top-level functions and function calls.
\end{itemize}
Besides, each feature is packed with 3 operations: evaluator, pretty
printer and type checker.

Having the feature set, we can synthesize different languages by selecting one
or more operations, and one or more data variants, as shown in \cref{fig:langs}.
For example \lstinline{arith} is a simple language of arithmetic expressions,
assembled from $\mathit{natF}$, $\mathit{boolF}$ and $\mathit{compF}$. On top of
that, we also define an evaluator, a pretty printer and a type checker. Note
that for some languages (e.g., \lstinline{simplenat}), since they have only one
kind of value, we only define an evaluator and a pretty printer. We thus obtain
12 languages and 30 operations in total. The complete language
\lstinline{mini-JS} contains all the features and supports all the operations.
Besides, we also define a combined algebra with the combined behavior of all the operations.
The reader can refer to our supplementary material for the source code of the case study.


\begin{table}[t]
  \centering
  \begin{small}
\begin{tabular}{|l||c|c|c||c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Language} & \multicolumn{3}{c||}{Operations} & \multicolumn{6}{c|}{Data variants}           \\ \cline{2-10}
                      & eval     & print     & check    & $\mathit{natF}$ & $\mathit{boolF}$ & $\mathit{compF}$ & $\mathit{logicF}$ & $\mathit{varF}$ & $\mathit{funcF}$ \\ \hline \hline
\lstinline$simplenat$             &   \cmark       & \cmark          &          &  \cmark    &       &       &        &      &       \\ \hline
\lstinline$simplebool$          &  \cmark        &  \cmark         &          &      &  \cmark     &       &        &      &       \\ \hline
\lstinline$natbool$       &  \cmark        & \cmark          & \cmark         & \cmark     & \cmark      &       &        &      &       \\ \hline
\lstinline$varbool$       &  \cmark        &  \cmark         &          &      & \cmark      &       &        & \cmark     &       \\ \hline
\lstinline$varnat$      &   \cmark       &  \cmark         &   &  \cmark    &     &       &        & \cmark      &       \\ \hline
\lstinline$simplelogic$  &  \cmark        &  \cmark         &          &      &   \cmark    &       &    \cmark    &      &       \\ \hline
\lstinline$varlogic$   &    \cmark      &   \cmark        &          &      &  \cmark     &       &  \cmark  &  \cmark    &       \\ \hline
\lstinline$arith$     &  \cmark  &  \cmark &  \cmark &  \cmark    &  \cmark     &  \cmark     &        &      &       \\ \hline
\lstinline$arithlogic$ &  \cmark   &  \cmark &  \cmark  & \cmark     &  \cmark     & \cmark      & \cmark       &      &       \\ \hline
\lstinline$vararith$        &  \cmark   &  \cmark  &  \cmark  & \cmark     &  \cmark     &  \cmark     &        & \cmark     &       \\ \hline
\lstinline$vararithlogic$  &  \cmark &  \cmark  &  \cmark  & \cmark & \cmark & \cmark &  \cmark & \cmark &       \\ \hline
\lstinline$mini-JS$  &  \cmark &  \cmark  &  \cmark  & \cmark & \cmark & \cmark &  \cmark & \cmark & \cmark      \\ \hline
\end{tabular}

  \end{small}
\caption{Overview of the languages assembled}
\label{fig:langs}
\end{table}


\section{Evaluation}
\label{sec:evaluate}

To evaluate \sedel's implementation of the case study,
\Cref{fig:sloc} compares the number of source lines of code
(SLOC, lines of code without counting empty lines and comments) for
\sedel's \emph{modular} implementation with the vanilla
\emph{non-modular} AST-based implementations in Haskell. The Haskell
implementations are just straightforward AST interpreters, which duplicate code across the multiple language
components.

Since \sedel is a new language, we
had to write various code that is provided in Haskell by the standard library,
so they are not counted for fairness of comparison. In the left part, for each
feature, we count the lines of the algebra interface (number beside the feature
name), and the algebras for the operations. In the right part, for each
language, we count the lines of ASTs, and those to combine previously
defined operations. For example, here is the code that is needed to make the
\lstinline{arith} language.
\lstinputlisting[linerange=537-553]{./examples/case_study.sl}% APPLY:linerange=ARITH
We only need 12 lines in total: 4 lines for the AST, and 8 lines to combine the operations.

Therefore, the total SLOC of \sedel's implementation is the sum of all the
lines in the feature and language parts (237 SLOC of all features plus 94 SLOC
of ASTs and operations). Although \sedel is considerably more verbose than a
functional language like Haskell, \sedel's modular implementation for 12 languages and 30
operations in total reduces approximately 60\% in terms of SLOC. The reason is
that, the more frequently a feature is reused by other languages directly or
indirectly, the more reduction we see in the total SLOC. For example,
$\mathit{natF}$ is used across many languages. Even though \lstinline{simplenat}
itself \emph{alone} has more SLOC ($40 = 7+23+7+3$) than that of Haskell (which
has 33), we still get a huge gain when implementing other languages.

Finally, we acknowledge the limitation of our case study in that SLOC is just
one metric and we have not measured any other metrics. Nevertheless we believe
that the case study is already non-trivial in that we need to solve EP. Note
that Scala traits alone are not sufficient on their own to solve EP. While there
are solutions to EP in both Haskell and Scala, they
introduce significant complexity, as explained in \cref{sec:ob}.



\begin{table}[t]
  \centering
  \begin{small}
  \begin{tabular}{|r|ccc||l|ccc|}
    \hline
     Feature & \textbf{eval} & \textbf{print} & \textbf{check} & Lang sedel & \sedel & \textbf{Haskell} & \textbf{\% Reduced}  \\
    \hline
    $\mathit{natF}$(7) & 23 & 7 & 39 & \lstinline$simplenat$ & 3 & 33 & 91\%  \\
    $\mathit{boolF}$(4) & 9 & 4 & 17 & \lstinline$simplebool$ & 3 & 16 & 81\% \\
    $\mathit{compF}$(4) & 12 & 4 & 20 & \lstinline$natbool$ & 5 & 74 & 93\% \\
    $\mathit{logicF}$(4) & 12 & 4 & 20 & \lstinline$varbool$ & 4 & 24 & 83\% \\
    $\mathit{varF}$(4) & 7 & 4 & 7 & \lstinline$varnat$ & 4 & 41 & 90\% \\
    $\mathit{funcF}$(3) & 10 & 3 & 9 & \lstinline$simplelogic$ & 4 & 28 & 86\% \\
     & & & & \lstinline$varlogic$ & 6 & 36 & 83\% \\
     & & & & \lstinline$arith$ & 8 & 94 & 91\% \\
     & & & & \lstinline$arithlogic$ & 8 & 114 & 93\% \\
     & & & & \lstinline$vararith$ & 8 & 107 & 93\% \\
     & & & & \lstinline$vararithlogic$ & 8 & 127 & 94\% \\
     & & & & \lstinline$mini-JS$ & 33 & 149 & 78\% \\
    \hline
    \textbf{Total} & & & 237 & & 331 & 843 & 61\% \\
    \hline
  \end{tabular}
  \end{small}
  \caption{SLOC statistics: \sedel implementation vs. vanilla AST implementation}
  \label{fig:sloc}
\end{table}
