
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Work}
\label{sec:related}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


There is a great deal of work related to this thesis. We have touched some most
relevant work (notably intersection types) in \cref{chap:background}. In this
chapter, we briefly review other related work, starting with a summary of two
most common approaches on coherence (\cref{sec:related:coherence}). We then
consider various existing mechanisms to foster modularity and code reuse in the
rest of this chapter.


\section{Coherence}
\label{sec:related:coherence}

In calculi that feature coercive subtyping, a semantics that interprets the
subtyping judgment by introducing explicit coercions is typically defined on
typing derivations rather than on typing judgments. A natural question that
arises for such systems is whether the semantics is \emph{coherent}, i.e.,
distinct typing derivations of the same typing judgment possess the same
meaning. Since \citet{Reynolds_1991} proved the coherence of a calculus with
intersection types, based on the denotational semantics for intersection types,
many researchers have studied the problem of coherence in a variety of typed
calculi. Below we summarize two commonly-found approaches in the literature.

\subsection{Normalization-based Approach}
The first approach is based on normalization. \citet{Breazu_Tannen_1991} proved
the coherence of a coercion translation from
\textsf{Fun}~\citep{cardelli1985understanding} extended with recursive types to
System F by showing that any two typing derivations of the same judgment are
normalizable to a unique normal derivation where the correctness of the
normalization steps is justified by an equational theory in System F.
\citet{Curien_1992} presented a translation of System F$_\leq$ into a calculus
with explicit coercions and showed that any derivations of the same judgment are
translated to terms that are normalizable to a unique normal form. Following the
same approach, \citet{SCHWINGHAMMER_2008} proved the coherence of coercion
translation from \citeauthor{Moggi_1991}'s computational lambda calculus~\citep{Moggi_1991} with
subtyping.


\subsection{Context-based Approach}

Central to the first approach is to find a normal form for a representation of
the derivation and show that normal forms are unique for a given typing
judgment. However, this approach cannot be directly applied to Curry-style
calculi, i.e., where the lambda abstractions are not type annotated. Also this
line of reasoning cannot be used when the calculus has general recursion.
\citet{biernacki2015logical} considered the coherence problem of coercion
semantics. Their criterion for coherence of the translation is
\emph{contextual equivalence} in the target calculus. They presented a
construction of logical relations for establishing so constructed coherence for
coercion semantics, showing that this approach is applicable in a variety of
calculi, including delimited continuations and control-effect subtyping.


Inspired by this approach, \citet{bi_et_al:LIPIcs:2018:9227} proposed the canonicity relation
to prove coherence for a calculus with disjoint intersection types and BCD
subtyping.
BCD subtyping in
our setting poses a non-trivial complication over
\citeauthor{biernacki2015logical}'s simple structural subtyping. Indeed, because
any two coercions between given types are behaviorally equivalent in the target
language, their coherence reasoning can all take place in the target language.
This is not true in our setting, where coercions can be distinguished by
arbitrary target programs, but not those that are elaborations of source
programs. (Recall that $ [[\x . pp1 x]]    $ and $ [[ \x . pp2 x]]    $ should be equated in our setting.)
Hence, we have to restrict our reasoning to the latter class, which is reflected
in a more complicated notion of contextual equivalence and our logical
relation's non-trivial treatment of pairs.
As we have shown in \cref{chap:coherence:poly}, constructing a
suitable logical relation for \fnamee is challenging. On the one hand, the
original approach by Alpuim et al.~\citep{alpuimdisjoint} in \fname does not work
any more due to the addition of BCD subtyping. On the other hand, simply
combining System F's logical relation with \namee's canonicity relation does not
work as expected, due to the issue of well-foundedness. To solve the problem, we
employ immediate substitutions and a restriction to predicative instantiations.


\section {BCD Subtyping and Decidability}

The BCD type system was first introduced by \citet{Barendregt_1983}. It is
derived from a filter lambda model in order to characterize exactly the strongly
normalizing terms. The BCD type system features a powerful subtyping relation,
which serves as a base for our subtyping relation.
\citet{DBLP:journals/corr/BessaiDDCd15} show how to type classes and mixins in a
BCD-style record calculus with a merge-like operator~\citep{bracha1990mixin}
that only operates on records, and they only study a type assignment system. The
decidability of BCD subtyping has been shown in several
works~\citep{pierce1989decision, Kurata_1995, Rehof_2011, Statman_2015}.
\citet{laurent2012intersection} formalized the relation in Coq in order to
eliminate transitivity cuts from it, but his formalization does not deliver an
algorithm. Only recently, \citet{Laurent18b} presents a general way of defining
a BCD-like subtyping relation extended with generic contravariant/covariant type
constructors that enjoys the ``sub-formula property'' (read decidability). The
key idea is to generalize the form of subtyping from $[[A <: B]]$ to $[[A1]],
\dots, [[An]] \vdash [[B]]$, which is interpreted as meaning $[[ A1 & ... & An <: B]]$.
Here is his subtyping system instantiated with singleton records, adapted to our setting:
\begin{mathpar}
  \inferrule*{ }{ [[int]] \vdash [[int]]  } \and
  \inferrule*{ }{ \vdash [[Top]]  } \and
  \inferrule*{ \vdash [[B]]  }{ \vdash [[A -> B]]  } \and
  \inferrule*{ \vdash [[A]]  }{ \vdash [[ {l : A}   ]]  } \and
  \inferrule*{ \Gamma, \Delta \vdash [[C]]  }{ \Gamma, [[int]], \Delta \vdash [[C]] } \and
  \inferrule*{ \Gamma, \Delta \vdash [[C]]  }{ \Gamma, [[Top]], \Delta \vdash [[C]] } \and
  \inferrule*{ \Gamma, \Delta \vdash [[C]]  }{ \Gamma, [[A -> B]], \Delta \vdash [[C]] } \and
  \inferrule*{ \Gamma, \Delta \vdash [[C]]  }{ \Gamma, [[ {l : B}  ]], \Delta \vdash [[C]] } \and
  \inferrule*{ \Gamma \vdash [[A]] \\ \Gamma \vdash [[B]]  }{ \Gamma \vdash [[A & B]] } \and
  \inferrule*{ \Gamma, [[A]], [[B]], \Delta \vdash [[C]]  }{ \Gamma, [[A & B]], \Delta \vdash [[C]] } \and
  \inferrule*{ [[A]] \vdash [[A1]] \\ \dots \\ [[A]] \vdash [[An]] \\  [[B1]], \dots, [[Bn]] \vdash [[B]]  } { [[A1 -> B1]], \dots, [[An -> Bn]] \vdash [[A -> B]]  } \and
  \inferrule*{ [[A1]], \dots , [[An]] \vdash [[B]]  } {  [[ {l : A1} ]], \dots, [[{l : An}]] \vdash [[ {l : B} ]]  }
\end{mathpar}
The first two rules are the base cases. The third and forth rules deal with
cases where $[[B]]$ is a ``top-like'' type. The next four rules are the
weakening rules for integers, top types, function types and singleton records.
The next two rules are the introduction and elimination rules for intersections.
The last two rules combine the function distributivity rule with usual function
subtyping, and record distributivity rule with usual record subtyping,
respectively. \citeauthor{Laurent18b} proved in Coq that $[[ A ]] \vdash [[B]]$
if and only if $[[ A <: B ]]$. % Based on \citeauthor{Statman_2015}'s work~\citep{Statman_2015},
% \citet{bessaiextracting} present a formally verified subtyping algorithm in Coq.
Our Coq formalization follows a different idea based on Pierce's decision
procedure~\citep{pierce1989decision}, which is shown to be easily extensible to
records, parametric (disjoint) polymorphism and corresponding
distributivity rules. In the course of our mechanization we identified several
mistakes in Pierce's proofs, as well as some important missing lemmas.
More recently,
\citet{muehlboeck2018empowering} presented a
decidable algorithmic system (proved in Coq)
with union and intersection types. Similar to \fnamee,
their system also has distributive subtyping rules. They also
discussed the addition of polymorphism, but left a Coq formalization
for future work. In their work they regard intersections of disjoint
types (e.g., $[[string & int]]$) as uninhabitable, which is different
from our interpretation.
As a consequence, coherence is a non-issue for them.
Finally,
it would be interesting to study an efficient subtyping algorithm in normal
practice. As noted by \citet{reynolds1997design}, however, the worst-case
inefficiency is inevitable. In fact, any typechecker for languages using
intersection types is PSPACE-hard.




\section{Intersection types, Merge Operator and Polymorphism}

\newcommand{\tikzcircle}[2][black,fill=black]{\tikz[baseline=-0.5ex]\draw[#1,radius=#2] (0,0) circle ;}%
\newcommand{\halfcircle}{\tikz[baseline=-0.5ex]{\draw[black, fill=white] (0, 0.07) arc (90:270:0.07); \draw[black, fill=black](0, -0.07) arc (-90:90:0.07);}}
\newcommand{\emptycircle}{\tikzcircle[black,fill=white]{2pt}\xspace}
\newcommand{\fullcircle}{\tikzcircle{2pt}\xspace}


Forsythe~\citep{reynolds1988preliminary} has intersection types and a merge-like
operator. However to ensure coherence, various restrictions were added to limit
the use of merges.
Forsythe only permits $p_1 ,, p_2$ when $p_2$ is either an
lambda abstraction or a record, whose meaning ``overrides'' the corresponding
type of meaning of $p_1$. For instance, there is a rule regarding lambda
abstraction that says (adapted to our syntax):
\[
  \inferrule*{ \Gamma \vdash \lam{x}{p_2} : \theta_1 \rightarrow \theta_2  }{ \Gamma \vdash (p_1 ,, \lam{x}{p_2}) : \theta_1 \rightarrow \theta_2  }
\]
which means that in a merge of two functions, the second one always takes
precedence to the first one. In contrast, our typing rule for merges is more
fine-grained in the sense that both functions are retained as long as they are
disjoint.
\citet{Castagna_1992} proposed a coherent calculus $\lambda \&$ to study
overloaded functions. $\lambda \&$ has a special merge operator
that works on functions only. % Like ours, they also impose well-formedness
% conditions on the formation of a (functional) merge. However, those conditions
% operate on function types only, and it is not clear how to generalize them to
% arbitrary types.
\citet{dunfield2014elaborating} proposed a calculus (which we call \dname) that
shows significant expressiveness of type systems with unrestricted intersection
types and a (unrestricted) merge operator. However, because of his unrestricted
merge operator (allowing $[[1,,2]]$), his calculus lacks coherence.
\citet{lasselambda}'s \lname enriched \dname with BCD subtyping and
computational effects, but he did not address coherence. The coherence issue for
a calculus similar to \dname was first addressed in
\oname~\citep{oliveira2016disjoint} with the notion of disjointness, but at the
cost of dropping unrestricted intersections, and a strict notion of coherence
(based on $\alpha$-equivalence). Later \citet{bi_et_al:LIPIcs:2018:9227}
improved calculi with disjoint intersection types by removing several
restrictions, adopted BCD subtyping and a semantic notion of coherence (based on
contextual equivalence) proved using canonicity. The combination of intersection
types, a merge operator and parametric polymorphism, while achieving coherence
was first studied in \fname~\citep{alpuimdisjoint}, which serves as a foundation
for \fnamee. However, \fname suffered the same problems as \oname. Additionally
in \fname a bottom type is problematic due to interactions with disjoint
polymorphism and the lack of unrestricted intersections. The issues can be
illustrated with the well-typed \fnamee expression $[[ \ X ** Bot . \ x : X . x
,, x ]]$. In this expression the type of $[[x ,, x]]$ is $[[ X & X ]]$. Such a
merge does not violate disjointness because the only types that $[[X]]$ can be
instantiated with are top-like, and top-like types do not introduce incoherence.
In \fname a type variable $[[X]]$ can never be disjoint to another type that
contains $[[X]]$, but (as the previous expression shows) the addition of a
bottom type allows expressions where such (strict) condition does not hold. In
\fnamee, we removed those restrictions, extended BCD subtyping with
polymorphism, and proposed a more powerful logical relation for proving
coherence. \Cref{fig:compare} summarizes the main differences between the
aforementioned calculi, where \fullcircle $=$ yes, \emptycircle $=$ no, and
\halfcircle\ $=$ syntactic coherence.

There are also several other calculi with intersections and polymorphism. Pierce
proposed $\mathsf{F}_{\land}$~\citep{pierce1991programming}, a calculus combining
intersection types and bounded quantification. Pierce translates
$\mathsf{F}_{\land}$ to System F extended with products, but he left coherence
as a conjecture. More recently, \citet{castagna2014polymorphic}
proposed a polymorphic calculus with set-theoretic type connectives
(intersections, unions, negations). But their calculus does not include a merge
operator. \citet{Castagna_2017} also proposed a gradual type
system with intersection and union types, but also without
a merge operator.


\begin{figure}[t]
  \centering
  \newcolumntype{L}{>{\raggedright\arraybackslash}p{4cm}}
  \newcolumntype{C}{>{\centering\arraybackslash}p{1.2cm}}
\begin{tabular}{LCCCCCC} \toprule
  & \dname & \oname & \lname  & \namee & \fname  & \fnamee \\ \midrule
Disjointness &  \emptycircle &  \fullcircle &  \emptycircle  &    \fullcircle   & \fullcircle   &   \fullcircle   \\
Unrestricted intersections &  \fullcircle &  \emptycircle &  \fullcircle  &  \fullcircle &   \emptycircle   &   \fullcircle   \\
BCD subtyping &  \emptycircle & \emptycircle &  \fullcircle  &  \fullcircle             &  \emptycircle         &  \fullcircle  \\
Polymorphism  &  \emptycircle &  \emptycircle  &  \emptycircle  &  \emptycircle &  \fullcircle  &  \fullcircle \\
Coherence &  \emptycircle &  \halfcircle &  \emptycircle  &  \fullcircle &   \halfcircle   &   \fullcircle   \\
Bottom type &  \emptycircle & \emptycircle &  \fullcircle  &  \emptycircle &  \emptycircle & \fullcircle   \\
  \bottomrule
\end{tabular}
\caption{Summary of intersection calculi}
  \label{fig:compare}
\end{figure}

\section{Row polymorphism and bounded polymorphism}
\label{sec:related:row}

Row polymorphism was originally proposed by \citet{wand1987complete}
as a mechanism to enable type inference for a simple object-oriented language
based on recursive records. These ideas were later adopted into type systems for
extensible records~\citep{Harper:1991:RCB:99583.99603, leijen2005extensible,
  gaster1996polymorphic}. % Cardelli and
% Mitchell~\cite{cardelli1989operations} define three primitive operations on
% records: \emph{selection}, \emph{restriction} and \emph{extension}.
Our merge operator can be seen as a generalization of record
extension/concatenation, and selection is also built-in. In contrast
to most record calculi, restriction is not a primitive operation in \namee and \fnamee,
but can be simulated via subtyping. Disjoint quantification can
simulate the \emph{lacks} predicate often present in systems
with row polymorphism.
Recently \citet{morrisrow} presented a
typed language, generalizing and abstracting existing systems
of row types and row polymorphism.
\citet{alpuimdisjoint}
informally studied the relationship between row polymorphism and disjoint
polymorphism, but it would be interesting to study such relationship more
formally. The work of  Morris and McKinna may be interesting for such
study in that it gives a general framework for row type systems.

Bounded quantification is currently the dominant mechanism in major mainstream object-oriented languages
supporting both subtyping and polymorphism.
% , and it features in essentially all
% major mainstream OO languages.
\fsub~\citep{cardelli1985understanding} provides a
simple model for bounded quantification, but type-checking in full \fsub is
proved to be undecidable~\citep{pierce1994bounded}.
Pierce's thesis~\citep{pierce1991programming} discussed the relationship between calculi
with simple polymorphism and intersection types and bounded quantification. He
observed that there is a way to ``encode'' many forms of bounded quantification
in a system with intersections and pure (unbounded) second-order
polymorphism. That encoding can be easily adapted to \fnamee:
\[
[[ \/ X <: A . B ]] \defeq [[ \ X ** Top . [ A & X / X] B  ]]
\]
The idea is to replace bounded quantification by (unrestricted)
universal quantification and all occurrences of $[[X]]$
by $[[A & X]]$ in the body. Such an encoding seems to indicate
that \fnamee could be used as a decidable alternative to (full) \fsub.
It is worthwhile to note that this encoding does not
work in \fname because $[[A & X]]$ is not well-formed ($[[X]]$ is not
disjoint to $[[A]]$). In other words, the encoding requires
unrestricted intersections.


\section{Typed First-Class Classes/Mixins/Traits}

First-class classes have been used in Racket~\citep{DBLP:conf/aplas/FlattFF06},
along with mixin support, and have shown great practical value. For example,
DrRacket IDE~\citep{DBLP:journals/jfp/FindlerCFFKSF02} makes extensive use of
layered combinations of mixins to implement text editing features. The topic of
first-class classes with static typing has been explored by
\citet{DBLP:conf/oopsla/TakikawaSDTF12} in Typed Racket. They designed a gradual
type system that supports first-class classes. Of particular interest is their
use of row polymorphism to type mixins. For example, \lstinline{modal_mixin}
from \cref{sec:trait:overview} implemented in Typed Racket has type:
\begin{lstlisting}
(All (r / on-key toggle-mode)
     (Class ([on-key : (String -> Void)] | r)) ->
     (Class ([toggle-mode : (-> Void)] [on-key : (String -> Void)] | r)))
\end{lstlisting}
As with our use of disjoint polymorphism, row polymorphism can express
constraints on the presence or absence of members.
% Unlike disjoint polymorphism,
% row polymorphism prohibits forgetting class members. While this is reasonable in
% the setting of mixins, in some cases, a function taking one class as an argument
% can return another class that has fewer methods. For example, in \sedel we can write:
% \lstinputlisting[linerange=100-100]{./examples/overview2.sl}% APPLY:linerange=FOO
% where \lstinline{foo} drops \lstinline{bar} from its argument trait
% \lstinline{t}, which is impossible to express using row polymorphism.
As a consequence, Typed Racket ends up with two subtyping mechanisms: one for
first-class classes (via row polymorphism) and the other for objects (via normal
width subtyping). In contrast, \sedel uses only one mechanism---i.e., disjoint
polymorphism---to deal with both.


More recently, \citet{DBLP:conf/ecoop/LeeASP15} proposed a model for typed
first-class classes based on tagged objects. Like our development, the semantics
of their source language is defined by a translation into a target language. One
notable difference to \sedel is that they require the use of a variable rather
than an expression in the \lstinline{extends} clause, whereas we do not have
this restriction. In their source language, subclasses define subtypes, which
limits its applicability to extensible designs. Also their target calculus is
significantly more complex than ours due to the use of dependent function types
and dependent sum types. As they admitted, they omit inheritance in their
formalization.

Racket also supports a \emph{dynamically typed model} of first-class
traits~\citep{DBLP:conf/aplas/FlattFF06}. However, unlike Racket's first-class
classes and mixins, there is no type system supporting the use of first-class
traits. A key difficulty is \emph{statically} detecting conflicts. In the mixin
model this is not a problem because conflicts are implicitly resolved using the
order of composition. As far as we know, \sedel is the first design for typed
first-class traits.



\section{Mixin-Based Inheritance}

\citeauthor{bracha1990mixin}'s seminal paper~\citep{bracha1990mixin} extends
Modula-3 with mixins. Since then, many mixin-based models have been
proposed~\citep{flatt1998classes,bono1999core, ancona2003jam}. Mixin-based
inheritance requires that mixins are composed linearly, and as such, conflicts
are resolved implicitly. In comparison, the trait model in \sedel requires
conflicts to be resolved explicitly.  Note that conflict
detection is essential in expressing composition operators for object algebras,
without running into ambiguities. \citeauthor{bracha1992programming}'s Jigsaw
framework~\citep{bracha1992programming} formalized mixin composition, along with
a rich trait algebra including merge, restrict, select, project, overriding and
rename operators. \citet{LAGORIO201286} proposed \textsc{FJig} that reformulates
Jigsaw constructs in a Java-like setting. \citet{DBLP:conf/oopsla/AllenBC03}
described how to add first-class generic types---including mixins---to object-oriented
languages with nominal typing. \citet{Corradi_2012} described an extension of
\textsc{FJig} that integrates modular composition and nesting of Java-like
classes. It features a set of composition operators that allow to manipulate
nested classes at any depth level. In all of these systems, classes and mixins,
though they enjoy static typing, are still second-class constructs, and thus
their systems cannot express dynamic inheritance.


\section{Trait-Based Inheritance}

Traits were originally proposed by \citet{scharli2003traits}, and later formalized by ~\cite{Ducasse_2006} as a mechanism
for fine-grained code reuse to overcome many limitations of class-based
inheritance. The original proposal of traits were implemented in the
dynamically typed class-based language \textsc{Squeak/Smalltalk}. Since then
various formalizations of traits in a Java-like (statically typed) setting have
been proposed~\citep{fisher2004typed,scharli2003traitsformal,chai_trait,
  JOT:issue_2006_05/article4}. In most of the above proposals, trait composition
complements class-based inheritance. \sedel, in the spirit of \emph{pure trait-based programming languages}~\citep{BETTINI2013521, BETTINI2017419},
embraces traits as the sole mechanism for code reuse. The deviation from
traditional class-based inheritance is not only because of its simplicity, but
also because we need a very \emph{dynamic} form of inheritance. In comparison to
the traditional trait mode, traits in \sedel have the following differences:
\begin{enumerate}
\item traditional traits cannot be instantiated but only composed with a class,
  whereas traits in \sedel can be instantiated directly;
\item traditional traits cannot take constructor parameters whereas ours can;
\item the trait system in \sedel lacks a proper notion of inheritance
  relationship, e.g., in the traditional trait model, if the \emph{same}
  method is obtained more than once via different paths, there is no conflict.
  This is not the case in \sedel;
\item and finally traits in \sedel are first-class and support dynamic
  inheritance.
\end{enumerate}




\section{Family Polymorphism}

There has been much work on family polymorphism since \citeauthor{Ernst_2001}'s
original proposal~\citep{Ernst_2001}. Family polymorphism provides an elegant
solution to the expression problem. Although a simple Scala solution does exist
without requiring family polymorphism (e.g., see \citet{wang2016expression}), Scala does not support nested composition:
programmers need to manually compose all the classes from multiple extensions.
Generally speaking, systems that support family polymorphism can be divided into
two categories: those that support \emph{object families} and those that
support \emph{class families}. The original object family approach of
\textsc{Beta }(e.g., virtual classes~\citep{Madsen_1989}) treats nested classes as
attributes of objects of the family classes, whereas in class families,
classes are nested in other classes. The former choice is considered more
expressive~\citep{ErnstVirtual}, but requires a complex type system usually
involving dependent types. The object and class family approaches have even been
combined by the work on Tribe~\citep{pubsdoc:tribe-virtual-calculus}.

\paragraph{Object families.}

Virtual classes~\citep{Madsen_1989} as introduced in
\textsc{Beta}~\citep{LehrmannMadsen:1993:OPB:221048} are based on object
families. However, the virtual class mechanism in \textsc{Beta} is known to be unsound~\citep{bruce1998statically}.
Path-dependent types are used to ensure type safety for virtual types and
virtual classes in the calculus \textsc{vc}~\citep{ErnstVirtual}. One distinctive
difference from our calculi is that \textsc{vc} follows the mixin-style by
allowing the rightmost class to take precedence, whereas in \namee conflicts are
detected statically and resolved explicitly.

\paragraph{Class families.}

Concord~\citep{jolly2004simple}, Jx~\citep{Nystrom_2004} and
J\&~\citep{Nystrom:2006} follow the class family approach, where nested classes
and types are attributes of the family classes directly.
% Unlike virtual classes, subclass and subtype relationships are preserved by inheritance: the
% overriding class is also a subtype of the class it overrides.
%Nested inheritance
%does not support generic types. As we discussed in \cref{sec:diss}, \namee can be
%easily extended to incorporate parametric polymorphism.
Jx supports \emph{nested inheritance}, a class family mechanism that allows
nesting of arbitrary depth. J\& is a language that supports \emph{nested
  intersection}, building on top of Jx. Similar to our calculi, intersection
types play an important role in J\&, which are used to compose packages/classes.
However, J\& does not have a merge-like operator. When conflicts arise, prefix
types can be exploited to resolve the ambiguity. J\&$_s$~\citep{Qi:2009} is an
extension of the Java language that adds class sharing to J\&.
\citet{SAITO_2007} identified a minimal, lightweight set of language features to
enable family polymorphism,

Compared with those systems, which usually focus on getting a relatively complex
Java-like language with family polymorphism, our work on \namee focuses on a
minimal calculus that supports nested composition. We have shown that a calculus
with the merge operator and a variant of BCD subtyping captures the essence of nested
composition. Moreover, \namee enables new insights on the subtyping relations of
families. Our goal in this thesis is not to support full family polymorphism
which, besides nested composition, also requires dealing with other features
such as self types~\citep{bruce95thistype,saito09matching} and mutable state.
But we expect to investigate those features in the future.




\section{Languages with More Advanced Forms of Inheritance}

\textsc{Self}~\citep{ungar1988self} is a dynamically typed, prototype-based
language with a simple and uniform object model. \textsc{Self}'s inheritance
model is typical of what we call \emph{mutable inheritance}, because an
object's parent slot may be assigned new values at run time. Mutable inheritance
is rather unstructured, and oftentimes access to any clashing methods will
generate a ``messageAmbiguous'' error at run time. Although \sedel's dynamic
inheritance is not as powerful as mutable inheritance, its static type system
can guarantee that no such errors occur at run time.
Eiffel~\citep{meyer1987eiffel} supports a sophisticated class-based multiple
inheritance with deep renaming, exclusion and repeated inheritance. Of
particular interest is that in Eiffel, name collisions are considered
programming errors, and ambiguities must be resolved explicitly by the
programmer (by means of renaming). In this regard, \sedel is quite like Eiffel.
However, the type system in \sedel is more lenient in that two identically named
methods with different signatures can coexist.
Grace~\citep{DBLP:journals/jot/NobleBBHJ17, DBLP:conf/ecoop/0002HNB16} is an
object-based language designed for education, where objects are created by
\emph{object constructors}.
% In that regard, Grace is similar to \namee in that
% both are not class-based.
Since Grace has mutable fields, it has to consider
many concerns when it comes to inheritance, resulting in a rather complex
inheritance mechanism with various restrictions.
% For example, Grace imposes the
% constraint that the object being inherited must be \emph{fresh}. The effect of
% the freshness constraint is that the expression in the inherit clause must
% generate a new object. As a consequence, the expression after
% \lstinline{inherit} could not be a variable, which seems to preclude
% dynamic inheritance.
Since \sedel is pure, a relatively simple
% delegation-based
encoding of traits with late binding of \lstinline{self}
suffices for our applications. Grace's support for multiple inheritance is
based on what they call \emph{instantiable traits}.
% Still the freshness constraint applies.
We believe that there is plenty to be learned from Grace's design of traits if
we want to extend our trait model with features such as mutable state.
\textsc{MetaFJig}~\citep{SERVETTO2014219} (an extension of \textsc{FJig})
supports \emph{dynamic trait replacement}~\citep{chai_trait, BETTINI2013907,
  Ducasse_2006}, a feature for changing the behavior of an object at run time by
replacing one trait for another. More recently, a Java-like language called
Familia~\citep{Zhang_2017} were proposed to combine subtyping polymorphism,
parametric polymorphism and family polymorphism.



\section{Module Systems}

In parallel to OOP, the ML module system originally proposed by
\citet{MacQueen_1984} also offers powerful support for flexible program
construction. There is a large body of work on ML modules. Supporting
\emph{data abstraction} is the primary focus of the module mechanism in ML. It
ensures \emph{implementer-side} data abstraction by allowing the implementer
of a module to ``hide'' specific implementation behind an abstract interface. It
also supports a form of \emph{client-side} data abstraction where a client can
develop and compile a module independently from the modules on which it depends,
via the ``functor'' mechanism. One major limitation of the traditional ML module
systems is the lack of support for mutually recursive modules. There are several
proposals of extending ML with recursive
modules~\citep{Crary_1999,Rossberg_2013, Russo_2001}. Mixin modules in the
Jigsaw framework~\citep{Bracha92modularitymeets} provides a suite of operators
for adapting and combining modules. The MixML module
system~\citep{Rossberg_2013} incorporates mixin module composition, while
retaining the full expressive powerful of ML modules. There is also work on
elaborating the semantics of module systems into a smaller, well-established
internal language. \citet{ROSSBERG_2014} showed that plain System F is
sufficient as an internal language for conventional ML modules.
Furthermore, \citet{Rossberg_2015} proposed a redesign of ML in which modules are truly
first-class values, thus unifying the core and module layers into one language.

Module systems usually put more emphasis on supporting data abstraction. Support
for data abstraction adds considerable complexity, which is not needed in
\sedel. \sedel is focused on OOP and supports, among others, method overriding,
self references and dynamic dispatching, which (generally speaking) are all
missing features in module systems.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Thesis"
%%% org-ref-default-bibliography: "../Thesis.bib"
%%% End:
