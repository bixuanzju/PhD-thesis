%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and Future Work}
\label{chap:conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusion}




\section{Future Work}

In this section we discuss some areas where future research might extend and/or
complement the work described in this thesis.

\subsection{On Categorical Semantics}
\label{sec:category}

An interesting avenue for future work is to give a categorical semantics of
disjoint intersection types. The main reason for doing so is that, as
\citet{reynolds1988preliminary} nicely put it:
\begin{quote}
  ``by formulating succinct definitions in terms of a mathematical theory of
  great generality, we gain an assurance that our language will be uniform and
  general.''
\end{quote}
Using category theory as the basis for the type structure of a programming
language has a long history. \citet{lambek1985cartesian} discovered that
simply-typed lambda calculus can be interpreted in any Cartesian closed
category. \citet{Reynolds_1991} gives a category-theoretic presentation of a
lambda calculus extended to include records, fixed points and
intersection types, much similar to our \namee. Of particular interest to us is
his method for proving coherence. Let $[[D]]$ denote derivations of typing, then
the interpretation of a derivation $[[ D ; GG |- ee : A ]]$ is a morphism
$\bra{[[ D ; GG |- ee : A ]]} : \bra{[[GG]]} \rightarrow \bra{[[A]]} $ in a
suitable ``semantic'' category (i.e., being Cartesian closed and possessing
certain limits). Proving coherence in this presentation then amounts to
establishing the commutativity of all diagrams of the following
form\footnote{The proof actually needs a stronger inductive hypothesis.}:
\[
\begin{tikzcd}
\bra{[[  GG   ]]} \arrow[rrr, "\bra{[[ D1 ; GG |- ee : A  ]]}", bend left] \arrow[rrr, "\bra{[[ D2 ; GG |- ee : A  ]]} "', bend right] &  &  & \bra{[[ A ]]}
\end{tikzcd}
\]


\paragraph{Properties of Intersection Types.}

The key component of Reynolds' method is the interpretation of intersection
types. For the sake of precision in what follows, we pause to give some basic
properties of intersection types that are first proved by \citet{Reynolds_1991}.
We say two types $[[A]]$ and $[[B]]$ are equivalent, written $[[ A == B ]]$,
when $[[ A <: B ]]$ and $[[B <: A]]$. From the subtyping rules in
\cref{fig:subtype_decl}, we can derive the following equalities:

\begin{proposition}[$[[A == B]]$]\label{prop:1}
\begin{align*}
  [[A1 & (A2 & A3) ]]  &\approx  [[(A1 & A2) & A3]] \\
  [[ Top & A ]] &\approx [[A]] \\
  [[ A & Top ]] &\approx [[A]] \\
  [[A1 & A2 ]]  &\approx  [[ A2 & A1 ]] \\
  [[A & A ]]  &\approx  [[ A ]] \\
  [[ {l : A1 & A2}   ]] &\approx [[  {l : A1}  & {l : A2} ]] \\
  [[  A -> A1 & A2  ]] &\approx [[  (A -> A1) & (A -> A2)   ]] \\
  [[  {l : Top}    ]] &\approx [[  Top   ]] \\
  [[  A -> Top  ]] &\approx [[  Top   ]]
\end{align*}
\end{proposition}

It can be shown that every pair of types has a \textit{least upper bound} (unique up to $\approx$-equivalence). The following suffices to compute a least
upper bound, $[[A =/ B]]$\footnote{Note that the meta-function $\sqcup$, unlike $\&$, is not a type constructor.},
of any types $[[A]]$ and $[[B]]$:

\begin{proposition}[$[[ A =/ B   ]]$] \label{prop:2}
\begin{align*}
  [[  A =/ B   ]] &\approx [[B =/ A]] \\
  [[  A =/ Top   ]] &\approx [[Top]] \\
  [[  A1 =/ (A2 & A3)  ]] &\approx [[  (A1 =/ A2) & (A1 =/ A3)  ]] \\
  [[  pri =/ {l : A} ]] &\approx [[  Top  ]] \\
  [[  pri =/ (A1 -> A2) ]] &\approx [[  Top  ]] \\
  [[  {l : A} =/ (A1 -> A2) ]] &\approx [[  Top  ]] \\
  [[  {l : A1} =/ {l : A2} ]] &\approx [[  {l : A1 =/ A2}  ]] \\
  [[  {l1 : A1} =/ {l2 : A2} ]] &\approx [[  Top   ]] \quad \text{when} \ [[ l1 <> l2 ]] \\
  [[  (A1 -> A1') =/ (A2 -> A2') ]] &\approx [[  (A1 & A2) -> (A1' =/ A2')  ]]
\end{align*}
\end{proposition}


\paragraph{Connecting with Disjointness.}

With these properties stated, it turns out that our disjointness rules, as
given in \cref{fig:disjoint}, can be compactly formulated using $\approx$ and $\sqcup$:

\begin{theorem} \label{thm:disjoint_spec}
  $[[A ** B]]$ if and only if $[[   A =/ B == Top  ]]$.
\end{theorem}
\begin{proof}
  By induction on the derivation of disjointness. An interesting case is \rref{D-arr}
  \[
    \drule{D-arr}
  \]
  \begin{longtable}[l]{l|l}
    $[[A2 =/ B2 == Top]]$  & By i.h \\
    $[[  (A1 -> A2) =/ (B1 -> B2) ]] \approx [[(A1 & B1) -> (A2 =/ B2)]]$ & By \cref{prop:2} \\
    $[[  (A1 -> A2) =/ (B1 -> B2) ]] \approx [[(A1 & B1) -> Top]]$ & By above equality \\
    $[[(A1 & B1) -> Top == Top]]$  & By \cref{prop:1} \\
    $[[  (A1 -> A2) =/ (B1 -> B2) == Top]]$ & By above equality
  \end{longtable}
\end{proof}

\begin{remark}
  We can view \cref{thm:disjoint_spec} as a specification of disjointness.
\end{remark}


\paragraph{Interpretation of Intersection Types.}

Following Reynolds, a subtyping derivation is interpreted as a morphism $ \bra{[[ A <: B ]]} : \bra{[[A]]} \rightarrow \bra{[[B]]} $ with two requirements:
\begin{enumerate}
\item For all types $[[A]]$ the morphism from $ \bra{[[A]]}$ to $\bra{[[A]]}$ must be an identity arrow.
\item Whenever $[[A <: B]]$ and $[[ B <: C  ]]$, the composition of $\bra{[[ A <: B ]]}$ and $\bra{[[  B <: C   ]]}$ must be equal to $\bra{[[  A <: C  ]]}$, i.e., $ \bra{[[ A <: B ]]} ; \bra{[[  B <: C  ]]} = \bra{[[A <: C]]}$. (Here ``;'' denotes composition in diagrammatic order.)
\end{enumerate}
These requirements actually make $ \bra{\cdot} $ a functor from the
preordered set of types (viewed as a category) to the semantic category of
choice.

\begin{remark}
By definition, whenever $[[ A == B ]]$ we say $\bra{[[  A  ]]}$ is \textit{isomorphic} to $\bra{[[ B ]]}$, written $\bra{[[ A ]]} \cong \bra{[[B]]}$.
\end{remark}

Now we consider $\bra{[[ A1 & A2  ]]}$ in the following steps:
\begin{enumerate}
\item By \rref{S-andL,S-andR}, there must be two morphisms, $\bra{[[ pp1 ]]} : \bra{[[A1 & A2]]} \rightarrow \bra{[[A1]]}  $ and $\bra{[[pp2]]} : \bra{[[A1 & A2]]} \rightarrow \bra{[[A2]]}  $
  \[
\begin{tikzcd}
  \bra{[[A1]]} &  & \bra{[[A2]]} \\
  & \bra{[[A1 & A2]]} \arrow[lu, "\pi_1"'] \arrow[ru, "\pi_2"] &
\end{tikzcd}
  \]
\item For any types $[[A1]]$ and $[[A2]]$, there exists a least upper bound $[[
  A1 =/ A2 ]]$ (\cref{prop:2}), and two morphisms $\bra{[[A1 <: A1 =/ A2]]} : \bra{[[A1]]} \rightarrow \bra{[[A1 =/ A2]]}$
  and $\bra{[[A2 <: A1 =/ A2]]} : \bra{[[A2]]} \rightarrow \bra{[[A1 =/ A2]]}$, and the following diagram should commute:
  \[
\begin{tikzcd}
  & \bra{[[  A1 =/ A2 ]]} &  \\
  \bra{[[A1]]} \arrow[ru, "\bra{[[A1 <: A1 =/ A2]]}"] &  & \bra{[[A2]]} \arrow[lu, "\bra{[[A2 <: A1 =/ A2]]}"'] \\
  & \bra{[[A1 & A2]]} \arrow[lu, "\pi_1"'] \arrow[ru, "\pi_2"] &
\end{tikzcd}
  \]

\item For every type $[[A]]$ such that $[[A <: A1]]$ and $[[A <: A2]]$, \rref{S-and} implies that $[[A <: A1 & A2]]$, thus
  a morphism from $\bra{[[  A ]]}$ to $\bra{[[  A1 & A2  ]]}$. Call this $\mu_0$. The following diagram should commute:
  \[
\begin{tikzcd}
  & \bra{[[  A1 =/ A2 ]]} &  \\
  \bra{[[A1]]} \arrow[ru, "\bra{[[A1 <: A1 =/ A2]]}"] &  & \bra{[[A2]]} \arrow[lu, "\bra{[[A2 <: A1 =/ A2]]}"'] \\
  & \bra{[[A1 & A2]]} \arrow[lu, "\pi_1"'] \arrow[ru, "\pi_2"] & \\
  & \bra{[[A]]} \arrow[u, "\mu_0"] \arrow[luu, "\bra{[[A <: A1]]}"] \arrow[ruu, "\bra{[[A <: A2]]}"'] &
\end{tikzcd}
  \]
\item Furthermore, in the above diagram, we replace $\bra{[[A]]}$ by an
  arbitrary object $s$ and $\bra{[[A <: A1]]}$ and $\bra{[[A <: A1]]}$ by any
  morphisms $f_1$ and $f_2$ that make the outer diamond commutes, and we require
  the ``mediating morphism'' $\mu_0$ from $s$ to $\bra{[[A1 & A2]]}$ to be unique. Specifically,
  we define $\bra{[[A1 & A2]]}$ by requiring the following diagram must commute:
  \[
\begin{tikzcd}
  & \bra{[[  A1 =/ A2 ]]} &  \\
  \bra{[[A1]]} \arrow[ru, "\bra{[[A1 <: A1 =/ A2]]}"] &  & \bra{[[A2]]} \arrow[lu, "\bra{[[A2 <: A1 =/ A2]]}"'] \\
  & \bra{[[A1 & A2]]} \arrow[lu, "\pi_1"'] \arrow[ru, "\pi_2"] & \\
  & s \arrow[u, "\mu_0", dotted] \arrow[luu, "f_1"] \arrow[ruu, "f_2"'] &
\end{tikzcd}
  \]
\end{enumerate}
Thus we have defined $\bra{[[A1 & A2]]}$ to be the \textit{pullback} of
$\bra{[[A1]]}$, $\bra{[[A2]]}$ and $\bra{[[A1 =/ A2]]}$.

\paragraph{Interpretation of Disjoint Intersection Types.}

Given the interpretation of intersection types, it is fairly straightforward to
give the interpretation of disjoint intersection types. First recall that if
$[[A ** B]]$ then $[[ A =/ B == Top ]]$ (\cref{thm:disjoint_spec}). Also we have
$\bra{[[Top]]} = 1$---i.e., the terminal object. By specializing $\bra{[[A1 =/ A2]]}$ to be the terminal object
($\bra{[[A1 <: A1 =/ A2]]}$ and $\bra{[[A2 <: A1 =/ A2]]}$ are then uniquely
determined), then the pullback ``degrades'' to the \textit{product} of
$\bra{[[A1]]}$ and $\bra{[[A2]]}$. In other words, the interpretation of
disjoint intersection types is given by the following theorem:
\begin{theorem}
  If $[[A1 ** A2]]$ then $\bra{[[A1 & A2]]} \cong \bra{[[A1]]} \times \bra{[[A2]]} $.
\end{theorem}
\begin{remark}
It is reassuring to see that this theorem justifies our translation of
disjoint intersection types into product types, from the categorical
perspective.
\end{remark}



\paragraph{Coherence, from the categorical perspective?}

What we have developed so far is the (categorical) interpretation of disjoint intersection
types. We are still half way through the ultimate goal of (re-)establishing
coherence, now from the categorical perspective. The main difficulty is that we
do not know yet how to interpret bidirectional typing judgment---i.e., what are
$\bra{[[GG |- ee => A]]}$ and $\bra{[[GG |- ee <= A]]}$, and in particular the
interpretation of the merge operator. As we mentioned, bidirectional type checking
(besides disjointness) is essential to coherence. It would be exciting to see
some research along the lines of the above, so that we may have a solid
mathematical foundation for type systems with disjoint intersection types.

\subsection{On Implicit Polymorphism}
\label{sec:implicit}

Another interesting and practically useful extension is to study (predicative)
implicit polymorphism, in the spirit of Haskell. Our \fnamee calculus features
explicit polymorphism in the sense that we need to provide types during type
applications. A classic example of implicit polymorphism is the identity
function $[[\x . x]]$ of type $[[\X . X -> X]]$. When applied to $1$, for
example, the type variable $[[X]]$ will be implicitly instantiated to $[[nat]]$.
Moreover, we are interested in \textit{higher-rank polymorphism}, allowing
polymorphic quantifiers to appear anywhere in a type. There are several
approaches in the literature~\citep{odersky1996putting, dunfield2013complete,
  jones2007practical}. Since our declarative type system is already based on
bidirectional type-checking, the work by \citet{dunfield2013complete} is
particularly relevant for us. It should not be difficult to adapt their approach
to our declarative system. Below we sketch out several typing rules for the initial design.

\paragraph{Declarative Subtyping.}

First we consider the subtyping rules. Obviously \rref{S-forall} needs to be modified.
We replace it with the following two rules:
\begin{mathpar}
  \drule{IS-allL} \and \drule{IS-allR}
\end{mathpar}
\Rref{IS-allL} says that a type $[[\X ** A1 . A2]]$ is a subtype of $[[B]]$ if
some instantiation $[[ [t / X] A2 ]]$ is a subtype of $[[B]]$. However, unlike
\citeauthor{dunfield2013complete}'s system, in our setting, not every monotype
$[[t]]$ works---those that do not respect the disjointness constraints should
not be considered, for the sake of coherence.
Otherwise, we would allow $[[ ((\x . x ,, 2) : \X ** nat . X -> X) 1 ]]$ to type check,
which would be a disaster.
\Rref{IS-allR} says that $[[A]]$
is a subtype of $[[\X ** B1. B2]]$ if we can show that $[[A]]$ is a subtype of
$[[B2]]$ in a context extended with $[[X ** B1]]$. It is not immediately obvious
that these two rules subsume \rref{S-forall}, and in particular what happens to ``a universal quantifier is contravariant in its
disjointness constraints'', which is very important in the original subtyping.
It can be shown that they do subsume \rref{S-forall}, as is evident by the
following derivation:
\[
\inferrule*[right=\rref*{IS-allR}]{  \inferrule*[right=\rref*{IS-allL}]{ \inferrule*[right=\rref*{FD-tvarL}]{ [[  A2 <: A1  ]]    }{[[  X ** A2 |- X ** A1  ]]}  \\ [[  X ** A2 |- B1 <: B2  ]]   }{[[X ** A2 |- \X ** A1. B1 <: B2]]}    }{ [[  empty |- \X ** A1. B1 <: \X ** A2 . B2  ]] }
\]


\paragraph{Typing Rules.}

Now we consider the typing rules. Most of the rules stay the same. We remove
\rref{FT-tabs,FT-tapp}, since the syntax now does not include type abstractions and
type applications. We add one rule:
\[
  \drule{FT-gen}
\]
\Rref{FT-gen} says that $[[ee]]$ has type $[[\X ** A . B]]$ if $[[ee]]$ has type $[[B]]$ in a context extended with $[[ X ** A  ]]$.
Application becomes a little more complex:
\[
  \drule{FT-appI}
\]
The problem is that the inferred type $[[A]]$ for $[[ee1]]$ could be a
polymorphic quantifier.
We need to eliminate universals until we
reach an arrow type. To achieve this, we use a matching judgment $[[DD |- A tri A1 -> A2]]$,
which says that we can synthesize an arrow type $[[A1 -> A2]]$ from $[[A]]$.
Once we get an arrow type $[[A1 -> A2]]$, we use $[[A1]]$ to check against $[[ee2]]$.
The matching judgment~\citep{siek2015refined, xie2018consistent}, first used in gradual type systems, is inductively defined as follows:
\begin{mathpar}
\drule{m-forall} \and \drule{m-arr}
\end{mathpar}
\Rref{M-forall}, as with \rref{IS-allL},
works by guessing instantiations of polymorphic quantifiers with the requirement
that the monotype $[[t]]$ must meet the disjointness constraints. \Rref{M-arr}
is trivial, returning $[[A1 -> A2]]$ as it is.

The above is only a sketch; we have not studied the declarative system in full,
nor its metatheory. One potential problem is that now subtyping and
disjointness are mutually recursive (e.g., \rref{IS-allL} uses disjointness and
\rref{FD-tvarL} uses subtyping), which might pose difficulty in terms of
formalization. For coherence, we estimate that the proof method described in
this thesis should still work.

\paragraph{Algorithmic System.}

Having a declarative system is only a start. The major challenge is the
corresponding algorithmic system. It is known that full type inference is
undecidable for intersection types. Some restrictions are obviously in order,
leading to different points in the design space in terms of how much can be
inferred. We are interested to see some research into the algorithmic system.


\subsection{Disjoint Polymorphism vs. Row Polymorphism}

Row polymorphism, first proposed by \citet{wand1987complete}, was intended as a
mechanism to enable type inference for a simple object-oriented language based
on recursive records. These ideas were later adopted into type systems for
extensible records~\citep{Harper:1991:RCB:99583.99603, gaster1996polymorphic}.
As we have alluded to in \cref{sec:merge}, row polymorphism alone cannot express
the \lstinline{merge} function. It would be interesting to study the
relationship between disjoint polymorphism and row polymorphism, and in
particular, whether the former subsumes the latter. As noted by
\citet{alpuimdisjoint}, disjoint polymorphism can already encode polymorphic
extensible records. For the sake of comparison, we pick the record calculus
$\lambda^{\|}$ of \citet{Harper:1991:RCB:99583.99603}---an explicitly-typed,
second-order calculus that features single-field records and a symmetric merge
operator. In $\lambda^{\|}$, \textit{compatibility constraints} are used to
capture negative information about fields. For example, $r_1 \# r_2 $ denotes the
assertion that the record types $r_1$ and $r_2$ have disjoint sets of labels. To
illustrate polymorphic extensible records in $\lambda^{\|}$,
\citeauthor{Harper:1991:RCB:99583.99603} show a function that takes two
``disjoint'' records $x_1$ and $x_2$, where $x_1$ has at least a field $l_1$ of
type $[[nat]]$ and $x_2$ has at least a field $l_2$ of type $[[nat]]$, and
returns the result of merging $x_1$ and $x_2$ (altering their syntax slightly):
\begin{align*}
  \Lambda \alpha_1 \# (\{ l_1 : [[nat]] \}, \{ l_2 : [[nat]] \}) .\  \Lambda \alpha_2 \# (\alpha_1 , \{l_1 : [[nat]]\} , \{ l_2 : [[nat]]   \}) . \\
  \qquad \lambda x_1 : (\alpha_1 \| \{ l_1 : [[nat]] \}) .\  \lambda x_2 : (\alpha_2 \| \{ l_2 : [[nat]] \}) .\ x_1 \| x_2
\end{align*}
where $r_1 \| r_2$ is the record type obtained by merging $r_1$ and $r_2$, and
is only defined if $r_1 \# r_2$. The same operator is overloaded to merge two
records on the term level. Central to their system is the \textit{constrained
  quantification} $\forall \alpha \# R .\ t $, where each record type variable is
associated with a list of \textit{compatibility assumptions} $R$, whose elements
are record types (including record type variables). The \textit{constrained type abstraction} $\Lambda \alpha \# R.\ e$
is used to create values of constrained quantification.


In \fnamee, we can use disjoint quantification to express their constrained
qualification, intersection types to merge record types, and the merge operator
to merge records. The function mentioned above can be written in \fnamee as
follows:
\begin{align*}
  \Lambda (\alpha_1 * [[ {l1 : nat} & {l2 : nat} ]]) .\  \Lambda (\alpha_2 * [[  X1 & {l1 : nat} & {l2 : nat} ]]) . \\
  \qquad \lambda x_1 : [[X1 & {l1 : nat}]] .\  \lambda x_2 : [[X2 & {l2 : nat}]] .\ x_1 ,, x_2
\end{align*}
However, the merge operator in \fnamee is more general than its counterpart in
$\lambda^{\|}$---i.e., it works on any expressions, not just records. Another
important difference is that their compatibility judgment $r_1 \# r_2$ actually
implies that their records must have distinct fields, whereas \fnamee accepts duplicate
fields as long as their types are disjoint.

Thus we believe \fnamee completely subsumes $\lambda^{\|}$. To support this
claim, a straightforward approach is to translate their type system into
\fnamee, and argue that
\begin{inparaenum}[(1)]
\item the translation is type-safe (i.e., it type check in \fnamee);
\item whatever is ill-typed in $\lambda^{\|}$, so is its translation in \fnamee.
\end{inparaenum}


\subsection{Other Extensions}

\paragraph{Recusive Types}


\paragraph{Union Types}

\paragraph{Nominal Typing}


\paragraph{Mutable State}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Thesis"
%%% org-ref-default-bibliography: ../Thesis.bib
%%% End:
